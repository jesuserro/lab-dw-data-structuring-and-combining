{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25d7736c-ba17-4aff-b6bb-66eba20fbf4e",
   "metadata": {
    "id": "25d7736c-ba17-4aff-b6bb-66eba20fbf4e"
   },
   "source": [
    "# Lab | Data Structuring and Combining Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cdfc70-44c8-478c-81e7-2bc43fdf4986",
   "metadata": {
    "id": "a2cdfc70-44c8-478c-81e7-2bc43fdf4986"
   },
   "source": [
    "## Challenge 1: Combining & Cleaning Data\n",
    "\n",
    "In this challenge, we will be working with the customer data from an insurance company, as we did in the two previous labs. The data can be found here:\n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv\n",
    "\n",
    "But this time, we got new data, which can be found in the following 2 CSV files located at the links below.\n",
    "\n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file2.csv\n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file3.csv\n",
    "\n",
    "Note that you'll need to clean and format the new data.\n",
    "\n",
    "Observation:\n",
    "- One option is to first combine the three datasets and then apply the cleaning function to the new combined dataset\n",
    "- Another option would be to read the clean file you saved in the previous lab, and just clean the two new files and concatenate the three clean datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "492d06e3-92c7-4105-ac72-536db98d3244",
   "metadata": {
    "id": "492d06e3-92c7-4105-ac72-536db98d3244"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de nulos a tratar: Customer                     2937\n",
      "State                        2937\n",
      "Gender                       3059\n",
      "Education                    2937\n",
      "Customer Lifetime Value      2944\n",
      "Income                       2937\n",
      "Monthly Premium Auto         2937\n",
      "Number of Open Complaints    2937\n",
      "Policy Type                  2937\n",
      "Vehicle Class                2937\n",
      "Total Claim Amount           2937\n",
      "dtype: int64\n",
      "Número de duplicados a tratar: 2939\n",
      "['Washington' 'Arizona' 'Nevada' 'California' 'Oregon' nan]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los datasets\n",
    "file1 = pd.read_csv('data/file1.csv')\n",
    "file2 = pd.read_csv('data/file2.csv')\n",
    "file3 = pd.read_csv('data/file3.csv')\n",
    "\n",
    "# Renombrar columnas para que coincidan\n",
    "file1.rename(columns={'ST': 'State', 'GENDER': 'Gender'}, inplace=True)\n",
    "file2.rename(columns={'ST': 'State', 'GENDER': 'Gender'}, inplace=True)\n",
    "\n",
    "# Reordenar columnas de file3 para que coincidan con file1 y file2\n",
    "file3 = file3[['Customer', 'State', 'Gender', 'Education', 'Customer Lifetime Value', 'Income', 'Monthly Premium Auto', 'Number of Open Complaints', 'Policy Type', 'Vehicle Class', 'Total Claim Amount']]\n",
    "\n",
    "# Reordenar columnas de file1 y file2 para que coincidan con file3\n",
    "file1 = file1[['Customer', 'State', 'Gender', 'Education', 'Customer Lifetime Value', 'Income', 'Monthly Premium Auto', 'Number of Open Complaints', 'Policy Type', 'Vehicle Class', 'Total Claim Amount']]\n",
    "file2 = file2[['Customer', 'State', 'Gender', 'Education', 'Customer Lifetime Value', 'Income', 'Monthly Premium Auto', 'Number of Open Complaints', 'Policy Type', 'Vehicle Class', 'Total Claim Amount']]\n",
    "\n",
    "# Combinar los datasets\n",
    "combined_data = pd.concat([file1, file2, file3], ignore_index=True)\n",
    "\n",
    "# Función para limpiar y estandarizar la columna 'Gender'\n",
    "def clean_gender(gender):\n",
    "    if pd.isna(gender):\n",
    "        return gender\n",
    "    gender = gender.strip().lower()\n",
    "    if gender in ['m', 'male']:\n",
    "        return 'M'\n",
    "    elif gender in ['f', 'female', 'femal']:\n",
    "        return 'F'\n",
    "    else:\n",
    "        return gender\n",
    "\n",
    "# Aplicar la función a la columna 'Gender'\n",
    "combined_data['Gender'] = combined_data['Gender'].apply(clean_gender)\n",
    "\n",
    "\n",
    "# Función para limpiar y estandarizar la columna 'State'\n",
    "def clean_state(state):\n",
    "    if pd.isna(state):\n",
    "        return state\n",
    "    state = state.strip().lower()\n",
    "    state_mapping = {\n",
    "        'cali': 'California',\n",
    "        'california': 'California',\n",
    "        'az': 'Arizona',\n",
    "        'arizona': 'Arizona',\n",
    "        'nv': 'Nevada',\n",
    "        'nevada': 'Nevada',\n",
    "        'or': 'Oregon',\n",
    "        'oregon': 'Oregon',\n",
    "        'wa': 'Washington',\n",
    "        'washington': 'Washington'\n",
    "    }\n",
    "    return state_mapping.get(state, state.capitalize())\n",
    "\n",
    "# Aplicar la función a la columna 'State'\n",
    "combined_data['State'] = combined_data['State'].apply(clean_state)\n",
    "\n",
    "# Calcula los null.sum de cada columna\n",
    "print(f\"Número de nulos a tratar: {combined_data.isnull().sum()}\")\n",
    "\n",
    "# Calcula los duplicated.sum de cada columna\n",
    "print(f\"Número de duplicados a tratar: {combined_data.duplicated().sum()}\")\n",
    "\n",
    "# Eliminar duplicados\n",
    "combined_data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Guardar el dataset combinado\n",
    "combined_data.to_csv('data/combined_data.csv', index=False)\n",
    "\n",
    "# Verificar los valores únicos en la columna 'Gender'\n",
    "print(combined_data['State'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b8a9e7-7db9-4604-991b-ef6771603e57",
   "metadata": {
    "id": "31b8a9e7-7db9-4604-991b-ef6771603e57"
   },
   "source": [
    "# Challenge 2: Structuring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a877fd6d-7a0c-46d2-9657-f25036e4ca4b",
   "metadata": {
    "id": "a877fd6d-7a0c-46d2-9657-f25036e4ca4b"
   },
   "source": [
    "In this challenge, we will continue to work with customer data from an insurance company, but we will use a dataset with more columns, called marketing_customer_analysis.csv, which can be found at the following link:\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/marketing_customer_analysis_clean.csv\n",
    "\n",
    "This dataset contains information such as customer demographics, policy details, vehicle information, and the customer's response to the last marketing campaign. Our goal is to explore and analyze this data by performing data cleaning, formatting, and structuring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa10d9b0-1c27-4d3f-a8e4-db6ab73bfd26",
   "metadata": {
    "id": "aa10d9b0-1c27-4d3f-a8e4-db6ab73bfd26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   unnamed:_0 customer       state  customer_lifetime_value response  \\\n",
      "0           0  DK49336     Arizona              4809.216960       No   \n",
      "1           1  KX64629  California              2228.525238       No   \n",
      "2           2  LZ68649  Washington             14947.917300       No   \n",
      "3           3  XL78013      Oregon             22332.439460      Yes   \n",
      "4           4  QA50777      Oregon              9025.067525       No   \n",
      "\n",
      "   coverage education effective_to_date employmentstatus gender  ...  \\\n",
      "0     Basic   College        2011-02-18         Employed      M  ...   \n",
      "1     Basic   College        2011-01-18       Unemployed      F  ...   \n",
      "2     Basic  Bachelor        2011-02-10         Employed      M  ...   \n",
      "3  Extended   College        2011-01-11         Employed      M  ...   \n",
      "4   Premium  Bachelor        2011-01-17    Medical Leave      F  ...   \n",
      "\n",
      "   number_of_policies     policy_type        policy  renew_offer_type  \\\n",
      "0                   9  Corporate Auto  Corporate L3            Offer3   \n",
      "1                   1   Personal Auto   Personal L3            Offer4   \n",
      "2                   2   Personal Auto   Personal L3            Offer3   \n",
      "3                   2  Corporate Auto  Corporate L3            Offer2   \n",
      "4                   7   Personal Auto   Personal L2            Offer1   \n",
      "\n",
      "   sales_channel  total_claim_amount  vehicle_class  vehicle_size  \\\n",
      "0          Agent          292.800000  Four-Door Car       Medsize   \n",
      "1    Call Center          744.924331  Four-Door Car       Medsize   \n",
      "2    Call Center          480.000000            SUV       Medsize   \n",
      "3         Branch          484.013411  Four-Door Car       Medsize   \n",
      "4         Branch          707.925645  Four-Door Car       Medsize   \n",
      "\n",
      "  vehicle_type month  \n",
      "0            A     2  \n",
      "1            A     1  \n",
      "2            A     2  \n",
      "3            A     1  \n",
      "4            A     1  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jesus\\AppData\\Local\\Temp\\ipykernel_5776\\42018454.py:17: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  marketing_data.fillna(method='ffill', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['College', 'Bachelor', 'High School or Below', 'Doctor', 'Master'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset\n",
    "marketing_data = pd.read_csv('data/marketing_customer_analysis_clean.csv')\n",
    "\n",
    "# Mostrar las primeras filas del dataset para inspección\n",
    "print(marketing_data.head())\n",
    "\n",
    "# Limpiar y formatear los datos según sea necesario\n",
    "# Por ejemplo, eliminar columnas innecesarias, manejar valores nulos, etc.\n",
    "\n",
    "# Ejemplo: Eliminar columnas innecesarias\n",
    "columns_to_drop = ['unnamed:_0']\n",
    "marketing_data.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Ejemplo: Manejar valores nulos\n",
    "marketing_data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Identificar las columnas categóricas\n",
    "categorical_columns = marketing_data.select_dtypes(include=['object']).columns\n",
    "# print(\"Columnas categóricas:\", categorical_columns)\n",
    "\n",
    "# Revisar los valores únicos en las columnas categóricas\n",
    "# for column in categorical_columns:\n",
    "    # print(f\"Valores únicos en '{column}':\")\n",
    "    # print(marketing_data[column].unique())\n",
    "    # print()\n",
    "\n",
    "# Crear una función para homogeneizar la columna 'education'\n",
    "def clean_education(education):\n",
    "    if pd.isna(education):\n",
    "        return education\n",
    "    education = education.strip().lower()\n",
    "    education_mapping = {\n",
    "        'high school or below': 'High School or Below',\n",
    "        'bachelor': 'Bachelor',\n",
    "        'college': 'College',\n",
    "        'master': 'Master',\n",
    "        'doctor': 'Doctor'\n",
    "    }\n",
    "    return education_mapping.get(education, education.capitalize())\n",
    "\n",
    "# Aplicar la función a la columna 'education'\n",
    "marketing_data['education'] = marketing_data['education'].apply(clean_education)\n",
    "\n",
    "# Elimina duplicados\n",
    "marketing_data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Guardar el dataset limpio\n",
    "marketing_data.to_csv('data/marketing_customer_analysis_cleaned.csv', index=False)\n",
    "\n",
    "marketing_data['education'].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df35fd0d-513e-4e77-867e-429da10a9cc7",
   "metadata": {
    "id": "df35fd0d-513e-4e77-867e-429da10a9cc7"
   },
   "source": [
    "1. You work at the marketing department and you want to know which sales channel brought the most sales in terms of total revenue. Using pivot, create a summary table showing the total revenue for each sales channel (branch, call center, web, and mail).\n",
    "Round the total revenue to 2 decimal points.  Analyze the resulting table to draw insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640993b2-a291-436c-a34d-a551144f8196",
   "metadata": {
    "id": "640993b2-a291-436c-a34d-a551144f8196"
   },
   "source": [
    "2. Create a pivot table that shows the average customer lifetime value per gender and education level. Analyze the resulting table to draw insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c7f2e5-3d90-43e5-be33-9781b6069198",
   "metadata": {
    "id": "32c7f2e5-3d90-43e5-be33-9781b6069198"
   },
   "source": [
    "## Bonus\n",
    "\n",
    "You work at the customer service department and you want to know which months had the highest number of complaints by policy type category. Create a summary table showing the number of complaints by policy type and month.\n",
    "Show it in a long format table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d09a8f-953c-448a-a5f8-2e5a8cca7291",
   "metadata": {
    "id": "e3d09a8f-953c-448a-a5f8-2e5a8cca7291"
   },
   "source": [
    "*In data analysis, a long format table is a way of structuring data in which each observation or measurement is stored in a separate row of the table. The key characteristic of a long format table is that each column represents a single variable, and each row represents a single observation of that variable.*\n",
    "\n",
    "*More information about long and wide format tables here: https://www.statology.org/long-vs-wide-data/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a069e0b-b400-470e-904d-d17582191be4",
   "metadata": {
    "id": "3a069e0b-b400-470e-904d-d17582191be4"
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
